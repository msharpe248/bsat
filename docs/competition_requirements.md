# Competition-Level SAT Solver Requirements

What it takes to build a solver that competes in the annual [SAT Competition](https://satcompetition.github.io/).

## Table of Contents

1. [Current State: BSAT vs Competition](#current-state-bsat-vs-competition)
2. [SAT Competition 2023-2024 Winners](#sat-competition-2023-2024-winners)
3. [The 10 Pillars of Competition-Level Solvers](#the-10-pillars-of-competition-level-solvers)
4. [Effort Estimation](#effort-estimation)
5. [Realistic Path Forward](#realistic-path-forward)
6. [Python SAT Resources](#python-sat-resources)
7. [Bottom Line](#bottom-line)

---

## Current State: BSAT vs Competition

### What BSAT Has ‚úÖ

From `src/bsat/cdcl.py`:
- ‚úÖ **Basic CDCL framework**
- ‚úÖ **Unit propagation**
- ‚úÖ **Conflict analysis** (1UIP - First Unique Implication Point)
- ‚úÖ **Clause learning**
- ‚úÖ **VSIDS heuristic** (Variable State Independent Decaying Sum)
- ‚úÖ **Non-chronological backtracking**
- ‚úÖ **Luby restart strategy**
- ‚úÖ **Educational clarity** (primary goal)

### The Gap ‚ö†Ô∏è

BSAT's own documentation states:
> "Note: This implementation prioritizes clarity over performance. It uses a simple unit propagation scheme rather than the two-watched-literal optimization."

**This is the fundamental difference between educational (BSAT's goal) and competition-level solvers.**

Key differences:
- **Language**: Python (educational) vs C/C++ (competition) = **10-100√ó speed difference**
- **Data structures**: Simple/clear vs highly optimized = **2-10√ó difference**
- **Algorithms**: Basic CDCL vs advanced techniques = **10-1000√ó on hard instances**
- **Tuning**: Minimal vs thousands of hours = **2-5√ó difference**

**Total gap**: ~**1000-10,000√ó slower** than competition winners

---

## SAT Competition 2023-2024 Winners

### SAT Competition 2024 Results

**Main Track Winners**:

1. **Kissat-sc2024** ü•áü•áü•á (3 Gold Medals)
   - Team: Armin Biere, Tobias Faller, Katalin Fazekas, Mathias Fleury, Nils Froleyks, Florian Pollitt
   - Institution: University of Freiburg, Germany
   - Performance: 153 SAT instances, 153 UNSAT instances solved
   - [GitHub: arminbiere/kissat](https://github.com/arminbiere/kissat)

2. **CaDiCaL** ü•à
   - Team: Armin Biere et al.
   - Evolution of MiniSat ideas with modern techniques
   - [GitHub: arminbiere/cadical](https://github.com/arminbiere/cadical)

**Cloud Track Winner**:

3. **MallobSat** ü•á (Parallel/Distributed)
   - Team: Dominik Schreiber
   - Performance: 356 instances solved (2.3√ó more than single-core)
   - Massively parallel portfolio solver

### SAT Competition 2023 Results

1. **Sbva-CaDiCaL** ü•á (Main Track)
   - Innovation: Bounded Variable Addition (BVA) preprocessing
   - Built on CaDiCaL 1.5.3 base
   - **Key insight**: Novel preprocessing > algorithmic changes

2. **CaDiCaL_vivinst** ü•á (Hack Track)
   - Innovation: Variable instantiation + clause vivification
   - 3rd place in main track on satisfiable instances

### Historical Context

**Evolution of Winners**:
- **1999**: Chaff (introduced VSIDS, two-watched literals)
- **2003**: MiniSat (minimal, elegant design - ~2,000 lines)
- **2007**: Glucose (LBD clause management)
- **2011**: Lingeling (aggressive inprocessing)
- **2019-2024**: Kissat (current state-of-the-art)

**Common thread**: ~20-year research pedigree, PhD-level teams, novel techniques

---

## The 10 Pillars of Competition-Level Solvers

### Pillar 1: Two-Watched Literals üî• CRITICAL

**Impact**: 100-1000√ó speedup in unit propagation (Boolean Constraint Propagation)

**Problem with BSAT's approach**:
```python
# BSAT: Check ALL clauses on every propagation
for clause in all_clauses:  # O(m) clauses
    if clause.is_unit():    # O(n) check
        propagate()
# Total: O(m¬∑n) per propagation
```

**Competition approach**:
```python
# Two-watched literals: Only check relevant clauses
watched[literal] = [clause1, clause2, ...]  # Clauses watching this literal

# When literal becomes false:
for clause in watched[literal]:  # Only affected clauses!
    # Find new watched literal: O(k) where k = clause length
    # Amortized O(1) per propagation
```

**How it works**:
1. Each clause "watches" 2 literals (not assigned to False)
2. Clause only revisited when watched literal becomes False
3. Find new watched literal or:
   - Clause satisfied ‚Üí skip
   - Other watched literal unassigned ‚Üí unit propagation
   - No valid watches ‚Üí conflict
4. **No work on backtracking** (watches stay valid!)

**First introduced**: Chaff solver (1999) - still used in ALL modern solvers

**Lines of code**: ~200-300 lines
**Complexity**: Moderate (pointer management tricky)
**Necessity**: **ABSOLUTELY REQUIRED** for competition

**References**:
- [Chaff paper (2001)](https://www.princeton.edu/~chaff/publication/DAC2001v56.pdf)
- [Modern SAT Solvers: Fast, Neat and Underused](https://codingnest.com/modern-sat-solvers-fast-neat-and-underused-part-3-of-n/)

---

### Pillar 2: VSIDS Refinements

**Impact**: 2-5√ó speedup through better branching decisions

**What BSAT has**: Basic heap-based VSIDS ‚úÖ
**What competition adds**: Highly tuned variant

**Key refinements**:

1. **Exponential moving average** (not linear decay)
```python
# BSAT: Simple decay
for var in variables:
    activity[var] *= 0.95

# Competition: Bump + decay
activity[var] += vsids_inc
vsids_inc *= 1/vsids_decay  # Increase bump amount
# Equivalent to EMA favoring recent conflicts
```

2. **Phase saving**: Remember last assigned polarity
```python
# When variable assigned:
phase[var] = value

# When branching on var again:
value = phase[var]  # Try same polarity first
# Often satisfies clauses immediately!
```

3. **Periodic rescoring** (prevent overflow)
```python
if max(activity.values()) > 1e100:
    for var in variables:
        activity[var] *= 1e-100  # Rescale all
```

4. **Target rate tuning**
```python
vsids_decay = 0.95  # Typical: 0.90-0.99
# Lower = forget old conflicts faster
# Higher = remember long-term patterns
# Optimal varies by instance!
```

**Why VSIDS works** (from research):
- Picks **bridge variables** connecting communities in conflict graph
- Focuses on high-centrality variables
- Adapts to problem structure dynamically
- Simple but remarkably effective

**Lines of code**: ~100-150 lines (refinements to existing)
**Necessity**: **REQUIRED** (BSAT has basics, needs tuning)

**References**:
- [Understanding VSIDS (2015)](https://arxiv.org/abs/1506.08905)
- [Original VSIDS paper (Chaff, 2001)](https://www.princeton.edu/~chaff/)

---

### Pillar 3: Clause Database Management (Glucose LBD)

**Impact**: 2-5√ó speedup on large instances through memory/cache optimization

**What BSAT has**: Stores all learned clauses
**What competition does**: Aggressive deletion based on quality

**The LBD (Literal Block Distance) metric** from Glucose solver:

```python
def compute_lbd(clause, assignments):
    """
    LBD = number of different decision levels in clause

    Low LBD = "glue clause" = high quality = KEEP
    High LBD = weak relevance = DELETE

    Example:
    Clause: (x ‚à® y ‚à® z)
    x assigned at level 2
    y assigned at level 2
    z assigned at level 5
    LBD = 2 (two distinct levels: {2, 5})

    LBD ‚â§ 3: "glue clause" - connects multiple decision points
    """
    levels = set()
    for lit in clause:
        if lit.variable in assignments:
            levels.add(assignments[lit.variable].decision_level)
    return len(levels)

# Clause management strategy
if lbd <= 3:
    keep_forever()  # Glue clauses are precious
else:
    # Delete periodically (every 5000-20000 conflicts)
    candidates_for_deletion.add(clause)
```

**Why delete clauses?**
1. **Memory**: 1M+ learned clauses = GB of RAM
2. **Cache locality**: Fewer clauses = better cache hit rate
3. **Propagation speed**: Less work in unit propagation

**Typical strategy**:
- Keep all clauses with LBD ‚â§ 3 (2-5% of learned)
- Keep recently learned clauses (last 10,000)
- Delete others every N conflicts
- Binary clauses (2 literals) always kept

**Lines of code**: ~200-300 lines
**Necessity**: **VERY IMPORTANT**
**First introduced**: Glucose solver (2007)

**References**:
- [Glucose paper (2009)](https://www.ijcai.org/Proceedings/09/Papers/074.pdf)
- [Glucose source code](https://github.com/audemard/glucose)

---

### Pillar 4: Inprocessing (Preprocessing During Search)

**Impact**: 10-100√ó speedup on hard instances through continuous simplification

**What BSAT has**: None (only initial preprocessing in separate module)
**What competition does**: Simplify formula during search

**Key techniques**:

#### 4.1 Vivification
Try to strengthen clauses:
```python
def vivify_clause(clause):
    """
    Can we satisfy this clause with fewer literals?

    Example: (a ‚à® b ‚à® c)
    Test: Can we satisfy with just (a ‚à® b)?
    If current assignments + (¬¨a ‚àß ¬¨b) ‚Üí conflict
    Then we don't need c! Replace with (a ‚à® b)
    """
    for subset in subsets(clause):
        if test_satisfiable(subset):
            return subset  # Shorter clause!
    return clause
```

#### 4.2 Variable Elimination
Remove variables appearing in few clauses:
```python
def eliminate_variable(var):
    """
    If var appears in k clauses, resolve them all

    Given: (a ‚à® b) and (¬¨a ‚à® c)
    Result: (b ‚à® c)  [resolved, eliminated 'a']

    Only do if #new_clauses < #old_clauses
    """
    positive_clauses = clauses_with(var, positive=True)
    negative_clauses = clauses_with(var, negative=True)

    if len(positive_clauses) * len(negative_clauses) < threshold:
        for pos in positive_clauses:
            for neg in negative_clauses:
                new_clause = resolve(pos, neg, var)
                add_clause(new_clause)
        remove_all_clauses_with(var)
```

#### 4.3 Subsumption (Continuous)
Remove redundant clauses:
```python
# (a ‚à® b) subsumes (a ‚à® b ‚à® c)
# Keep shorter clause, delete longer
```

#### 4.4 Bounded Variable Addition (BVA) ‚≠ê
**Key to Sbva-CaDiCaL's 2023 win**:
```python
def bounded_variable_addition():
    """
    Add auxiliary variable to simplify formula

    Given: (a ‚à® b ‚à® c) ‚àß (a ‚à® b ‚à® d)
    Add: x ‚Üî (a ‚à® b)  [new variable!]
    Result: (x ‚à® c) ‚àß (x ‚à® d) ‚àß (¬¨x ‚à® a ‚à® b) ‚àß (x ‚à® ¬¨a) ‚àß (x ‚à® ¬¨b)

    Often simpler for solver to handle
    """
```

**Scheduling**: Run inprocessing every N conflicts
- N = 5,000-100,000 depending on solver
- Too frequent = overhead
- Too rare = miss simplification opportunities

**Lines of code**: ~1,000-2,000 lines
**Complexity**: High
**Necessity**: **VERY IMPORTANT** (top solvers all do this)

**References**:
- [Inprocessing survey (Handbook of Satisfiability, 2021)](https://www.iospress.com/catalog/books/handbook-of-satisfiability-2)
- [BVA paper](https://fmv.jku.at/papers/EenMishchenkoSorensson-SAT05.pdf)

---

### Pillar 5: Restart Strategies

**Impact**: 10-50% speedup through better exploration

**What BSAT has**: Luby sequence ‚úÖ
**What competition uses**: More sophisticated strategies

**Modern approaches**:

#### 5.1 Glucose-style LBD-based restarts
```python
def should_restart():
    """
    Restart based on LBD trend

    If recent conflicts have low LBD:
      ‚Üí Making progress (connecting communities)
      ‚Üí Keep going!

    If recent conflicts have high LBD:
      ‚Üí Stuck in one area
      ‚Üí Restart!
    """
    recent_avg_lbd = avg(lbd_history[-100:])
    global_avg_lbd = avg(lbd_history)

    return recent_avg_lbd > global_avg_lbd * 1.25
```

#### 5.2 Reluctant Doubling
```python
def reluctant_doubling_restart():
    """
    Increase restart interval when making progress

    Start: restart every 100 conflicts
    If made progress: restart every 200 conflicts
    If made progress: restart every 400 conflicts
    If stuck: reset to 100
    """
```

#### 5.3 Blocking Restarts
```python
def should_block_restart():
    """
    Don't restart if trail is "good"

    Good trail = many recent assignments at low decision level
    Indicates formula is being simplified
    """
    return len(trail_at_level_0) > threshold
```

**BSAT's Luby sequence is fine for educational purposes**

**Necessity**: **MODERATE** (10-50% improvement over Luby)
**Lines of code**: ~100-200 lines

**References**:
- [Luby sequence paper (1993)](https://epubs.siam.org/doi/10.1137/0222043)
- [Glucose restart strategy](https://www.ijcai.org/Proceedings/09/Papers/074.pdf)

---

### Pillar 6: Conflict Analysis Refinements

**Impact**: 10-30% speedup through better learned clauses

**What BSAT has**: 1UIP (First Unique Implication Point) ‚úÖ
**What competition adds**: Optimizations

#### 6.1 Literal Minimization
Shrink learned clauses by 20-50%:
```python
def minimize_learned_clause(clause):
    """
    Remove redundant literals from learned clause

    Given learned: (a ‚à® b ‚à® c ‚à® d)

    Test: Is 'c' needed?
    Try: (a ‚à® b ‚à® d) ‚àß (¬¨a ‚àß ¬¨b ‚àß ¬¨d)
    If conflict ‚Üí 'c' is redundant! Remove it.

    Result: (a ‚à® b ‚à® d)  [shorter = more powerful]
    """
    for lit in clause:
        if can_imply_without(lit, clause):
            clause.remove(lit)
    return clause
```

#### 6.2 Binary Clause Fast Path
```python
def propagate_binary_clause(a, b):
    """
    Special handling for 2-literal clauses

    (a ‚à® b) is VERY common in learned clauses
    Don't use general propagation machinery

    If ¬¨a assigned ‚Üí directly assign b
    O(1) instead of O(clause_length)
    """
    if not a:
        assign(b, reason=(a, b))
```

#### 6.3 Lazy Implication Graph
```python
def analyze_conflict_lazy():
    """
    Don't build full implication graph up front
    Only compute needed parts during conflict analysis

    Saves memory and time
    """
```

**Lines of code**: ~200-300 lines
**Necessity**: **MODERATE**

**References**:
- [Clause minimization (MiniSat)](http://minisat.se/)
- [Binary clauses in Glucose](https://github.com/audemard/glucose)

---

### Pillar 7: Data Structure Optimization üî• CRITICAL

**Impact**: 2-10√ó speedup through cache/memory efficiency

**Why this matters**: Modern CPUs
- RAM access: ~100ns
- L1 cache: ~1ns
- **100√ó difference!**

#### 7.1 Cache Locality
**Bad** (BSAT-style - pointer chasing):
```python
class Clause:
    def __init__(self, literals):
        self.literals = literals  # List of Literal objects

clauses = [Clause(...), Clause(...), ...]  # List of objects
# Every clause access = pointer dereference = cache miss
```

**Good** (competition-style - flat memory):
```c
// Store clauses in one big array
uint32_t clause_db[10000000];  // Flat array

// Layout: [length, lit1, lit2, ..., length, lit1, lit2, ...]
// Example: [3, 5, -7, 12, 2, 3, -8, ...]
//          ‚îî‚îÄclause 1‚îÄ‚îò ‚îî‚îÄclause 2‚îÄ‚îò

// Access clauses by offset, not pointer
// All data contiguous = cache-friendly
```

#### 7.2 Bit Packing
```c
// Pack variable ID + polarity into 32 bits
// Bit 0: polarity (0=positive, 1=negative)
// Bits 1-31: variable ID

uint32_t encode_literal(int var, bool negated) {
    return (var << 1) | negated;
}

// Also pack clause metadata
uint64_t clause_header = (lbd << 32) | (length << 16) | flags;
```

#### 7.3 Custom Allocators
```c
// Pool allocation for clauses
// No malloc() in hot path!

char* clause_pool = malloc(100MB);
size_t pool_offset = 0;

void* allocate_clause(size_t size) {
    void* ptr = clause_pool + pool_offset;
    pool_offset += size;
    return ptr;  // No malloc() overhead!
}
```

#### 7.4 SIMD Possibilities
```c
// Process 8 literals at once using AVX2
__m256i literals = _mm256_load_si256(clause);
// Vectorized operations
```

**Why Python can't compete here**:
- Garbage collection pauses (10-100ms)
- Everything is a pointer (cache misses)
- No control over memory layout
- Dynamic typing overhead
- No SIMD instructions

**Lines of code**: ~500-1,000 lines
**Necessity**: **CRITICAL** (requires C/C++)

**References**:
- [Cache-efficient SAT solving](https://www.cs.princeton.edu/~chaff/)
- [MiniSat data structures](http://minisat.se/Papers.html)

---

### Pillar 8: Parallel/Portfolio Solving

**Impact**: 2-3√ó speedup with 8-16 cores, more with 100+ cores

**What BSAT has**: Single-threaded
**What cloud track winners use**: 100-1,000 cores

#### 8.1 Portfolio Approach
```python
# Run 8-16 different strategies in parallel
strategies = [
    {'vsids_decay': 0.90, 'restart': 'luby'},
    {'vsids_decay': 0.95, 'restart': 'glucose'},
    {'vsids_decay': 0.99, 'restart': 'reluctant'},
    # ... 13 more strategies
]

with ThreadPoolExecutor(16) as pool:
    futures = [pool.submit(solve, strategy) for strategy in strategies]
    # First to finish wins!
    result = next(as_completed(futures))
```

#### 8.2 Divide-and-Conquer (Cube-and-Conquer)
```python
def cube_and_conquer():
    """
    Phase 1 (Cube): Divide into subproblems
    - Use lookahead to split formula
    - Create 10,000-1,000,000 subproblems

    Phase 2 (Conquer): Solve in parallel
    - Each core takes subproblems from queue
    - CDCL on each subproblem
    """
    # Phase 1: Cubing (single-threaded)
    subproblems = lookahead_split(formula, target=100000)

    # Phase 2: Parallel conquering
    with ProcessPoolExecutor(1000) as pool:
        results = pool.map(cdcl_solve, subproblems)
```

**Used to solve**:
- Pythagorean triples problem (2016) - 800 cores, 2 days
- Schur number 5 (2017)
- Various open combinatorics problems

#### 8.3 Clause Sharing
```python
def share_learned_clauses():
    """
    Threads share learned clauses

    Only share "glue clauses" (LBD ‚â§ 2)
    - High quality
    - Small size
    - Low communication overhead
    """
    with shared_clause_db.lock():
        for clause in my_learned_clauses:
            if lbd(clause) <= 2:
                shared_clause_db.add(clause)
```

**Challenges**:
- Synchronization overhead
- Load balancing
- Memory contention
- Diminishing returns beyond 16-32 cores (for portfolio)

**Lines of code**: +2,000-5,000 lines
**Complexity**: Very high
**Necessity**: **NOT REQUIRED** for main track, essential for cloud track

**References**:
- [Cube-and-Conquer paper (2014)](https://arxiv.org/abs/1410.5158)
- [MallobSat (2024 cloud winner)](https://github.com/domschrei/mallob)
- [ManySAT (portfolio solver)](https://www.labri.fr/perso/lsimon/downloads/publications/ManySAT.pdf)

---

### Pillar 9: Implementation Language & Engineering üî• CRITICAL

**Impact**: 10-100√ó speedup from Python ‚Üí C/C++

#### 9.1 Python vs C Performance

**BSAT (Python)**:
```python
# Beautiful, readable, slow
def propagate(self, lit):
    for clause in self.clauses:
        if clause.is_unit():
            # Garbage collection pause
            # Dynamic dispatch
            # Object allocation overhead
```

**Competition (C)**:
```c
// Fast, optimized, harder to read
static inline int propagate(solver* s, lit l) {
    watch* ws = s->watches[l];  // Direct memory access
    watch* end = ws + s->watch_size[l];

    for (watch* w = ws; w != end; w++) {
        // No GC, no dynamic dispatch, cache-friendly
        // Compiler: inline, vectorize, optimize
    }
}
```

**Performance factors**:
1. **No garbage collection** (C manages memory manually)
2. **Static typing** (no dynamic lookup)
3. **Direct memory access** (no object indirection)
4. **Compiler optimizations** (O3, PGO, LTO)
5. **SIMD instructions** (process 4-8 literals at once)
6. **Inline assembly** possible

#### 9.2 Solver Code Sizes

| Solver | Language | Lines of Code | Notes |
|--------|----------|---------------|-------|
| **MiniSat** | C++ | ~2,000 | Core solver, famous for minimalism |
| **Glucose** | C++ | ~3,000 | MiniSat + LBD management |
| **Lingeling** | C | ~10,000 | Aggressive inprocessing |
| **CaDiCaL** | C++ | ~15,000 | Modern techniques |
| **Kissat** | C | ~20,000 | State-of-the-art 2024 |
| **BSAT** | Python | ~1,000 | Educational, not competitive |

#### 9.3 Real-World Comparison

```
Benchmark: 100 SAT instances (medium difficulty)

BSAT (Python + CDCL):     1000 seconds
MiniSat (C++):              10 seconds  (100√ó faster)
Glucose (C++):               5 seconds  (200√ó faster)
Kissat (C):                  1 second   (1000√ó faster)
```

**Why such huge differences?**
- Python: 100√ó slower baseline
- MiniSat: Good algorithm + C++
- Glucose: Better clause management
- Kissat: 20 years of refinement

#### 9.4 To Compete: Must Use C/C++

**No exceptions**. Top 100 solvers in SAT Competition:
- C/C++: 100%
- Python: 0%

**Why Python SAT solvers exist**:
- Education (like BSAT!) ‚úÖ
- Rapid prototyping
- Python bindings to C solvers (PySAT)

**Lines of code**: Complete rewrite (5,000-20,000 lines C)
**Necessity**: **ABSOLUTELY CRITICAL**

**References**:
- [MiniSat source](https://github.com/niklasso/minisat)
- [Kissat source](https://github.com/arminbiere/kissat)
- [CaDiCaL source](https://github.com/arminbiere/cadical)

---

### Pillar 10: Empirical Tuning

**Impact**: 2-5√ó speedup from parameter optimization

**What BSAT has**: Default parameters
**What competition does**: 1000s of hours of tuning

#### 10.1 Key Parameters to Tune

```python
# VSIDS
vsids_decay = 0.95           # Range: 0.90-0.99
vsids_increment = 1.0        # Range: 0.5-2.0
phase_saving = True

# Restarts
restart_base = 100           # Range: 50-500
restart_strategy = 'luby'    # luby, glucose, reluctant

# Clause management
learned_clause_limit = 10000 # Range: 5000-50000
deletion_interval = 5000     # Range: 2000-20000
lbd_threshold = 3            # Range: 2-5

# Inprocessing
inprocess_interval = 10000   # Range: 5000-100000
vivification_enabled = True
variable_elimination = True
subsumption_enabled = True
```

#### 10.2 Tuning Methods

**Manual tuning**:
```python
# Test on 1000 benchmark instances
for decay in [0.90, 0.92, 0.94, 0.95, 0.96, 0.98, 0.99]:
    results = run_benchmarks(decay)
    print(f"Decay {decay}: {results.avg_time}")
# Pick best
```

**Automated tuning** (used by competition winners):
- **SMAC** (Sequential Model-based Algorithm Configuration)
- **ParamILS** (Iterated Local Search)
- **GGA** (Gender-based Genetic Algorithm)

```python
# SMAC: Bayesian optimization over parameter space
from smac import SMAC

def objective(params):
    solver = create_solver(**params)
    return avg_time_on_benchmarks(solver)

tuner = SMAC(objective, parameter_space)
best_params = tuner.optimize(1000_iterations)
```

#### 10.3 Benchmark Suites

Competition tuning uses:
- **Industrial instances**: Hardware verification, planning
- **Crafted instances**: Pigeonhole, graph coloring, crypto
- **Random 3-SAT**: Phase transition (m/n ‚âà 4.26)

**1000+ instances** covering diverse problem types

#### 10.4 Time Investment

**Competition-winning teams**:
- 100-1000 hours of benchmarking
- Multiple years of incremental tuning
- Regression testing on every change
- Separate tuning for different tracks

**Diminishing returns**:
- First 80% of performance: 20% of effort
- Last 20% of performance: 80% of effort

**Lines of code**: Tuning scripts (1,000+ lines)
**Necessity**: **VERY IMPORTANT** (2-5√ó from good tuning)

**References**:
- [SMAC tool](https://github.com/automl/SMAC3)
- [SAT Competition benchmarks](https://satcompetition.github.io/)
- [Parameter tuning survey](https://www.cs.ubc.ca/~hoos/Publ/HooStu14.pdf)

---

## Effort Estimation

### Phase 1: Core Performance (6-12 months full-time)

**Goal**: Match MiniSat (~2004 level)

1. **Rewrite in C/C++** (2-3 months)
   - Port CDCL framework
   - Port CNF data structures
   - Port VSIDS
   - ~5,000 lines C++

2. **Implement two-watched literals** (1-2 months)
   - Core algorithm: 1 week
   - Debug and test: 3-7 weeks
   - ~300 lines, but tricky

3. **Optimize VSIDS** (1 month)
   - Phase saving
   - Exponential decay
   - Rescoring
   - ~150 lines

4. **Basic clause management** (1-2 months)
   - LBD computation
   - Periodic deletion
   - ~200 lines

5. **Data structure optimization** (2-3 months)
   - Flat clause storage
   - Bit packing
   - Cache-friendly layout
   - ~500 lines

**Result**: ~5,000-8,000 lines C++
**Performance**: Competitive with MiniSat (2004)
**Competition rank**: Top 50-100 (out of ~80 solvers)

---

### Phase 2: Modern Techniques (6-12 months full-time)

**Goal**: Match Glucose/Lingeling (~2012 level)

6. **Inprocessing** (2-4 months)
   - Vivification (1 month)
   - Variable elimination (1 month)
   - Subsumption (2 weeks)
   - BVA (1 month)
   - ~1,500 lines

7. **Advanced restart strategies** (1 month)
   - Glucose-style LBD restarts
   - Reluctant doubling
   - Blocking restarts
   - ~200 lines

8. **Conflict analysis refinements** (1-2 months)
   - Clause minimization (3 weeks)
   - Binary clause optimization (2 weeks)
   - Lazy implication graph (2 weeks)
   - ~300 lines

9. **Clause learning improvements** (1 month)
   - Better 1UIP
   - Minimization strategies
   - ~200 lines

10. **Empirical tuning** (ongoing)
    - Benchmark infrastructure
    - Parameter sweeps
    - Regression testing

**Result**: ~10,000-15,000 lines C++
**Performance**: Competitive with Glucose/Lingeling (2012)
**Competition rank**: Top 20-40

---

### Phase 3: State-of-the-Art (12-24 months full-time)

**Goal**: Top 10 in SAT Competition

11. **Novel preprocessing** (3-6 months)
    - Research new techniques
    - Implement BVA variants
    - Experimental approaches
    - ~1,000 lines

12. **Extreme optimization** (3-6 months)
    - Profile with perf/valgrind
    - Optimize hot paths
    - SIMD vectorization
    - Assembly for critical sections
    - ~500 lines + optimizations

13. **Parallel solving** (3-6 months)
    - Portfolio implementation
    - Clause sharing
    - Load balancing
    - ~2,000 lines

14. **Competition-specific tuning** (ongoing)
    - Tune on competition benchmarks
    - Multiple configurations
    - Track-specific optimization

**Result**: ~15,000-25,000 lines C++
**Performance**: State-of-the-art
**Competition rank**: Top 5-15

---

### Total Timeline

**Realistic estimates**:

| Path | Timeline | Team Size | Result |
|------|----------|-----------|--------|
| **Solo, part-time** | 5-10 years | 1 | Top 50 |
| **Solo, full-time** | 2-4 years | 1 | Top 20 |
| **Small team** | 1-2 years | 2-3 | Top 10-20 |
| **Research group** | 1-2 years | 3-5 | Top 5-10 |
| **Win competition** | 5-10+ years | 2-5 | 1st place |

**Prerequisites**:
- PhD in CS or equivalent experience
- Expert C/C++ programming
- Deep CDCL understanding
- Years of SAT research
- Competition participation experience

---

## Realistic Path Forward

### Path 1: Educational (BSAT's Current Mission) ‚úÖ

**Goal**: Teach SAT solving concepts

**Recommendations**:
1. ‚úÖ Keep Python (clarity > speed)
2. ‚úÖ Add educational two-watched literals
   - Simplified version with extensive comments
   - Shows the concept
   - 200-300 lines
   - 2-3√ó speedup (not 100√ó, but demonstrates idea)

3. ‚úÖ Add LBD clause management
   - Glucose-style scoring
   - Periodic deletion
   - 100-200 lines
   - Great teaching tool

4. ‚úÖ Add phase saving
   - Remember variable polarities
   - 50 lines
   - 20-30% improvement

5. ‚úÖ Add binary clause optimization
   - Fast path for 2-literal clauses
   - 100 lines
   - Educational value

**Effort**: 2-3 months part-time
**Result**: Even better educational tool
**Competition rank**: N/A (not the goal)

**This is the recommended path for BSAT!**

---

### Path 2: Research Contribution

**Goal**: Publish novel SAT technique

**Recommendations**:
1. Fork MiniSat or CaDiCaL (don't start from scratch!)
2. Implement 1-2 novel techniques:
   - New preprocessing approach
   - Novel restart strategy
   - Machine learning integration
   - Quantum-inspired heuristics
3. Benchmark extensively
4. Write paper
5. Submit to SAT Competition + conference

**Effort**: 6-12 months full-time
**Result**: Research paper, PhD chapter
**Competition rank**: Top 30-50 (with luck and good idea)

---

### Path 3: Production Use

**Goal**: Solve real problems fast

**Recommendations**: **Don't write your own!**

Use existing world-class solvers:
1. **PySAT** - Python bindings ‚úÖ
2. **Glucose/CaDiCaL/Kissat** - Call via subprocess ‚úÖ
3. **Z3** - SMT solver (includes SAT) ‚úÖ

**These are 1000√ó faster than any custom Python solver could be.**

---

### Path 4: Competition Entry

**Goal**: Place in top 10

**Requirements**:
- 2-4 years full-time development
- PhD-level expertise
- Novel algorithmic contribution
- Extreme optimization
- Team of 2-3 researchers
- Significant funding

**Expected result**:
- 50% chance: Top 50
- 25% chance: Top 20
- 10% chance: Top 10
- 2% chance: Top 3

**Honest assessment**: Not recommended unless:
- You're a PhD student (this is your research)
- You have novel algorithmic ideas
- You have 2-4 years to invest
- You want to become a SAT researcher

---

## Python SAT Resources

### Python Bindings to C Solvers (Recommended for Production)

#### 1. **PySAT** - Python SAT Toolkit üåü
- **What**: Python bindings to Glucose, MiniSat, CaDiCaL, Lingeling, and more
- **Performance**: Near-native C speed (thin wrapper)
- **Use case**: Production use, research prototyping
- **GitHub**: [pysathq/pysat](https://github.com/pysathq/pysat)
- **Install**: `pip install python-sat`

```python
from pysat.solvers import Glucose3

# Use Glucose solver from Python!
g = Glucose3()
g.add_clause([1, -2, 3])
g.add_clause([-1, 2])
g.solve()  # Fast C code
```

#### 2. **Python-SAT** (alternative name for PySAT)
- Same as above, just alternate naming

#### 3. **Z3 Python API**
- **What**: Microsoft's SMT solver (includes SAT)
- **Performance**: World-class
- **Use case**: SAT + SMT (theories)
- **GitHub**: [Z3Prover/z3](https://github.com/Z3Prover/z3)
- **Install**: `pip install z3-solver`

```python
from z3 import *

s = Solver()
x, y = Bools('x y')
s.add(Or(x, y))
s.check()  # sat/unsat
```

---

### Educational Python Implementations

#### 1. **BSAT** (This Project!) üéì
- **What**: Educational SAT solver package
- **Features**: 2SAT, DPLL, CDCL, Horn-SAT, XOR-SAT, etc.
- **Use case**: Learning SAT solving
- **GitHub**: [Your repo]

#### 2. **SATPy** - Simple SAT in Python
- **What**: Minimal DPLL implementation
- **GitHub**: [eliben/sat.py](https://github.com/eliben/sat)
- **Lines**: ~200 lines
- **Use case**: Understanding DPLL basics

#### 3. **PycoSAT** - Older Python Wrapper
- **What**: Python bindings to PicoSAT
- **Status**: Less maintained, use PySAT instead
- **GitHub**: [pypi/pycosat](https://pypi.org/project/pycosat/)

---

### Competition Solvers (C/C++ Source)

#### 1. **Kissat** - SAT Competition 2024 Winner ü•á
- **Language**: C (~20,000 lines)
- **GitHub**: [arminbiere/kissat](https://github.com/arminbiere/kissat)
- **Features**: State-of-the-art CDCL, inprocessing
- **License**: MIT
- **Use**: Study source code, call from Python via subprocess

#### 2. **CaDiCaL** - Runner-up, Highly Competitive
- **Language**: C++ (~15,000 lines)
- **GitHub**: [arminbiere/cadical](https://github.com/arminbiere/cadical)
- **Features**: Modern CDCL, clean code
- **License**: MIT
- **Use**: Easiest competition solver to read

#### 3. **MiniSat** - The Classic üìö
- **Language**: C++ (~2,000 lines core)
- **GitHub**: [niklasso/minisat](https://github.com/niklasso/minisat)
- **Features**: Minimal, elegant CDCL
- **License**: MIT
- **Use**: Best for learning, easiest to understand
- **Note**: Basis for 100+ derivative solvers

#### 4. **Glucose** - LBD Clause Management
- **Language**: C++ (~3,000 lines)
- **GitHub**: [audemard/glucose](https://github.com/audemard/glucose)
- **Features**: MiniSat + LBD deletion
- **License**: Custom (research use)

#### 5. **Lingeling, Plingeling, Treengeling**
- **Language**: C
- **Author**: Armin Biere (same as Kissat/CaDiCaL)
- **Features**: Parallel variants
- **Download**: [fmv.jku.at/lingeling](http://fmv.jku.at/lingeling/)

#### 6. **CryptoMiniSat** - For Cryptography
- **Language**: C++ (~10,000 lines)
- **GitHub**: [msoos/cryptominisat](https://github.com/msoos/cryptominisat)
- **Features**: XOR clauses, Gaussian elimination
- **Use case**: Cryptanalysis

#### 7. **MapleSAT** - Machine Learning SAT
- **Language**: C++
- **GitHub**: [maple-sat](https://sites.google.com/view/maplecmsatsolvers/home)
- **Features**: Learning-based branching
- **Competition**: Multiple winners 2016-2018

---

### Benchmarks and Tools

#### 1. **SATLIB** - Benchmark Library
- **URL**: [satlib.org](https://www.cs.ubc.ca/~hoos/SATLIB/)
- **What**: 1000s of SAT instances
- **Categories**: Random, industrial, crafted

#### 2. **SAT Competition**
- **URL**: [satcompetition.github.io](https://satcompetition.github.io/)
- **What**: Annual competition, benchmarks, results
- **Years**: 2002-present

#### 3. **DIMACS Format Tools**
- Standard CNF format used by all solvers
- BSAT has DIMACS support built-in!

---

### Educational Resources

#### 1. **Books**

- **Handbook of Satisfiability (2021)** üìò
  - 1500 pages, comprehensive
  - [IOS Press](https://www.iospress.com/catalog/books/handbook-of-satisfiability-2)

- **The Art of Computer Programming Vol 4B** (Knuth, 2022)
  - Section on SAT solving
  - [Addison-Wesley](https://www-cs-faculty.stanford.edu/~knuth/taocp.html)

- **Decision Procedures** (Kroening & Strichman)
  - Chapter on SAT/SMT
  - Textbook level

#### 2. **Online Courses**

- **CS-E3220** (Aalto University, Finland)
  - [Course website](https://users.aalto.fi/~tjunttil/2020-DP-AUT/)
  - Excellent SAT solver notes

- **SAT/SMT Summer School**
  - Annual summer school
  - [sat-smt.codes](http://sat-smt.codes/)

#### 3. **Tutorials**

- **Modern SAT Solvers: Fast, Neat and Underused**
  - [codingnest.com series](https://codingnest.com/modern-sat-solvers-fast-neat-and-underused-part-1-of-n/)
  - Practical guide

- **SAT Solver Etudes**
  - [Philip Zucker's blog](https://www.philipzucker.com/python_sat/)
  - Python implementations

#### 4. **Papers** (Classics)

- **Chaff (2001)**: Two-watched literals, VSIDS
  - [Princeton Chaff page](https://www.princeton.edu/~chaff/)

- **MiniSat (2003)**: Minimal elegant design
  - [MiniSat page](http://minisat.se/Papers.html)

- **Glucose (2009)**: LBD clause management
  - [IJCAI paper](https://www.ijcai.org/Proceedings/09/Papers/074.pdf)

---

### Calling Solvers from Python

#### Example: Using PySAT
```python
from pysat.solvers import Glucose3
from pysat.formula import CNF

# Create formula
cnf = CNF()
cnf.append([1, 2, 3])    # (x1 ‚à® x2 ‚à® x3)
cnf.append([-1, -2])      # (¬¨x1 ‚à® ¬¨x2)

# Solve
with Glucose3(bootstrap_with=cnf) as solver:
    if solver.solve():
        print(f"SAT: {solver.get_model()}")
    else:
        print("UNSAT")
```

#### Example: Calling Kissat via Subprocess
```python
import subprocess

# Write DIMACS file
with open('formula.cnf', 'w') as f:
    f.write('p cnf 3 2\n')
    f.write('1 2 3 0\n')
    f.write('-1 -2 0\n')

# Call kissat
result = subprocess.run(['kissat', 'formula.cnf'],
                       capture_output=True, text=True)

if 's SATISFIABLE' in result.stdout:
    print("SAT")
elif 's UNSATISFIABLE' in result.stdout:
    print("UNSAT")
```

#### Example: Using Z3
```python
from z3 import *

# High-level API
x, y, z = Bools('x y z')
solver = Solver()
solver.add(Or(x, y, z))
solver.add(Or(Not(x), Not(y)))

if solver.check() == sat:
    model = solver.model()
    print(f"x={model[x]}, y={model[y]}, z={model[z]}")
```

---

## Bottom Line

### To Build a Competition-Winning SAT Solver:

**Requirements**:
- üìä ~20,000 lines of highly optimized C code
- üß† PhD-level expertise in SAT solving algorithms
- ‚è∞ 5-10+ years of development and refinement
- üë• Team of 2-5 expert researchers
- üî¨ Novel algorithmic contributions (BVA, new heuristics, etc.)
- üéØ Thousands of hours of empirical tuning
- üí∞ Research funding and institutional support
- üìà Incremental improvements building on decades of SAT research

**Competition winners**:
- Kissat (2024): Armin Biere (20+ years SAT research)
- CaDiCaL (2023): Same team, building on MiniSat/Lingeling
- Glucose (2007-2013): PhD researchers at CRIL, France
- MiniSat (2003+): Niklas E√©n (15+ years SAT research)

**These aren't "better programmers" - they're researchers with decades of experience, novel techniques, and continuous refinement.**

---

### BSAT's Mission: Education ‚úÖ

**What BSAT is**:
- ‚úÖ Excellent educational tool
- ‚úÖ Clear, readable implementation
- ‚úÖ Teaches core SAT concepts
- ‚úÖ Multiple solver types (2SAT, DPLL, CDCL, Horn, XOR, WalkSAT)
- ‚úÖ Comprehensive documentation
- ‚úÖ Perfect for learning

**What BSAT is NOT**:
- ‚ùå Competition-level solver
- ‚ùå Production-ready for large instances
- ‚ùå Aiming for maximum performance

**This is by design and is the correct choice!**

---

### Recommended Actions for BSAT

#### Option A: Stay Educational (Recommended) ‚úÖ
Keep Python, keep clarity, add:
1. Educational two-watched literals (with extensive comments)
2. LBD clause management (demonstrate Glucose)
3. Phase saving (small improvement, easy to add)
4. More examples and documentation

**Effort**: 2-3 months part-time
**Result**: Even better teaching tool
**Impact**: Help 1000s learn SAT solving

#### Option B: Research Fork
- Fork MiniSat/CaDiCaL in C++
- Implement novel technique
- Submit to competition + write paper
- Keep BSAT separate as educational tool

**Effort**: 6-12 months full-time
**Result**: Research contribution, possible PhD chapter

#### Option C: Use Existing Solvers for Production
- Install PySAT: `pip install python-sat`
- Call Glucose/Kissat/CaDiCaL
- Get world-class performance immediately
- Focus on problem encoding, not solver internals

**Effort**: 1 day to integrate
**Result**: 1000√ó faster than custom Python solver

---

### The Honest Truth

**SAT Competition winners**:
- 10-20 years of incremental development
- Building on 60+ years of SAT research (Davis-Putnam 1960 ‚Üí present)
- PhD-level teams
- Novel algorithmic breakthroughs
- Brutal C-level optimization
- Thousands of hours of tuning

**BSAT's value is in education, not competition.**

Teaching the next generation of SAT researchers is arguably MORE valuable than one more competition entry. MiniSat (2003) never won competitions after 2005, but it influenced 100+ derivative solvers and taught thousands of students.

**BSAT can be the "MiniSat of Python" - the educational reference everyone learns from.** üéØ

---

## References

### SAT Competition
- **2024 Results**: [satcompetition.github.io/2024](https://satcompetition.github.io/2024/)
- **2023 Results**: [satcompetition.github.io/2023](https://satcompetition.github.io/2023/)
- **Historical**: [satcompetition.github.io](https://satcompetition.github.io/)

### Winner Solvers
- **Kissat**: [github.com/arminbiere/kissat](https://github.com/arminbiere/kissat)
- **CaDiCaL**: [github.com/arminbiere/cadical](https://github.com/arminbiere/cadical)
- **MiniSat**: [github.com/niklasso/minisat](https://github.com/niklasso/minisat)
- **Glucose**: [github.com/audemard/glucose](https://github.com/audemard/glucose)

### Python Resources
- **PySAT**: [github.com/pysathq/pysat](https://github.com/pysathq/pysat)
- **Z3**: [github.com/Z3Prover/z3](https://github.com/Z3Prover/z3)

### Papers
- **Chaff (2001)**: [princeton.edu/~chaff](https://www.princeton.edu/~chaff/)
- **VSIDS Analysis (2015)**: [arxiv.org/abs/1506.08905](https://arxiv.org/abs/1506.08905)
- **Glucose (2009)**: [IJCAI Proceedings](https://www.ijcai.org/Proceedings/09/Papers/074.pdf)
- **Two-watched literals**: [SAT Handbook Chapter](https://www.iospress.com/catalog/books/handbook-of-satisfiability-2)

### Educational
- **Handbook of Satisfiability**: [IOS Press](https://www.iospress.com/catalog/books/handbook-of-satisfiability-2)
- **Aalto Course**: [users.aalto.fi/~tjunttil](https://users.aalto.fi/~tjunttil/2020-DP-AUT/)
- **Modern SAT Solvers Blog**: [codingnest.com](https://codingnest.com/modern-sat-solvers-fast-neat-and-underused-part-1-of-n/)

---

## See Also

- [History of SAT Solving](history.md) - 60+ years from Davis-Putnam to Kissat
- [CDCL Solver Documentation](cdcl-solver.md) - BSAT's CDCL implementation
- [DPLL Solver Documentation](dpll-solver.md) - Foundation of modern SAT solving
- [Theory & References](theory.md) - Academic foundations
- [Reading List](reading-list.md) - Comprehensive bibliography

---

*This document provides an honest assessment of what it takes to compete at the highest level of SAT solving. BSAT's educational mission is valuable and important - not every solver needs to win competitions!*
